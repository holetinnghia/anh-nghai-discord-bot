from safetensors.torch import load_file, save_file
import torch
import os
import sys

# 1. T√™n file adapter sau khi train
INPUT_PATH = "adapters/adapter_model.safetensors"
# T√™n file adapter sau khi s·ª≠a l·ªói
OUTPUT_PATH = "adapters/adapter_model_fixed_final.safetensors"

print(f"üõ† B·∫Øt ƒë·∫ßu s·ª≠a ƒë·ªïi file: {INPUT_PATH}")

try:
    if not os.path.exists(INPUT_PATH):
        # Ki·ªÉm tra n·∫øu ch∆∞a ƒë·ªïi t√™n checkpoint th√†nh t√™n chu·∫©n th√¨ b√°o l·ªói
        raise FileNotFoundError(
            f"Kh√¥ng t√¨m th·∫•y file chu·∫©n {INPUT_PATH}. M√†y ph·∫£i ƒë·ªïi t√™n file 0000200_adapters.safetensors th√†nh adapter_model.safetensors tr∆∞·ªõc.")

    tensors = load_file(INPUT_PATH)
    new_tensors = {}

    for k, v in tensors.items():
        new_key = k

        # 1. Rename keys: .lora_a -> .lora_A.weight
        if k.endswith(".lora_a"):
            new_key = k.replace(".lora_a", ".lora_A.weight")
            v_fixed = v.T.contiguous()  # 2. TRANSPOSE (Xoay chi·ªÅu ma tr·∫≠n)

        elif k.endswith(".lora_b"):
            new_key = k.replace(".lora_b", ".lora_B.weight")
            v_fixed = v.T.contiguous()  # 3. TRANSPOSE (Xoay chi·ªÅu ma tr·∫≠n)

        else:
            v_fixed = v

        new_tensors[new_key] = v_fixed

    save_file(new_tensors, OUTPUT_PATH)
    print(f"‚úÖ S·ª≠a l·ªói th√†nh c√¥ng! File ƒë√£ l∆∞u t·∫°i: {OUTPUT_PATH}")

except Exception as e:
    print(f"‚ùå L·ªñI FATAL: {e}")
    sys.exit(1)